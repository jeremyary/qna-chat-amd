global: 
  pattern: amdllm

  amdllm:
    namespace: amd-llm
    build_envs: [] # http_proxy/https_prxy can be set here
    runtime_envs: []

    base_name: tei-embedding

    service:
      name: tei-embedding-service
      image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.6
      port: 8090
      pvc:
        size: 3Gi
      model_id: BAAI/bge-reranker-base
      # model_id: BAAI/bge-base-en-v1.5

    secret:
      env_name: HF_TOKEN
      name: hf-token-secret
      key: huggingface

#    tei_embedding:
#      name: tei-embedding
#      image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.6
#      pvc:
#        size: 3Gi
#      model_id: BAAI/bge-reranker-base
#      # model_id: BAAI/bge-base-en-v1.5
