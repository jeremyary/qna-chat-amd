kind: BuildConfig
apiVersion: build.openshift.io/v1
metadata:
  name: llm-tgi-amd-server
  namespace: {{ .Values.global.amdllm.namespace }}
spec:
  output:
    to:
      kind: "ImageStreamTag"
      name: "llm-tgi:latest"
  failedBuildsHistoryLimit: 5
  successfulBuildsHistoryLimit: 5
  nodeSelector: null
  postCommit: {}
  resources: {}
  runPolicy: SerialLatestOnly
  source:
    git:
      ref: {{ .Values.global.amdllm.llm_server_for_amd.git_ref }}
      uri: https://github.com/opea-project/GenAIComps.git
    type: Git
  strategy:
    type: Docker
    dockerStrategy:
      dockerfilePath: comps/llms/text-generation/tgi/Dockerfile
      {{- if .Values.global.amdllm.build_envs }}
      env:
      {{- range .Values.global.amdllm.build_envs }}
      - name: {{ .name }}
        value: {{ .value }}
      {{- end }}
      {{- end }}
  triggers:
  - type: ConfigChange
