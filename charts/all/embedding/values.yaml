global: 
  pattern: amdllm

  amdllm:
    namespace: amd-llm
    build_envs: [] # http_proxy/https_prxy can be set here
    runtime_envs: []

    service_name: embedding
    service_port: 5002
    container_port: 6000
    route_path: /v1/embeddings
    docker_file_Path: comps/embeddings/src/Dockerfile

    git_repo_uri: https://github.com/opea-project/GenAIComps.git
    image: quay.io/sgahlot/opea/embedding:latest
      # git_ref: 7c2e7f6 # make sure to validate buildconfig & other change scope before updating

    tei_service:
      name: tei-embedding-service
      port: 8091
      env_var_name: TEI_EMBEDDING_ENDPOINT

    env:
      - name: HOME
        value: /tmp/temp-data
      - name: PYTHONPATH
        value: /home/user/.local/lib/python3.11/site-packages:/home/user:/home

    volume:
      - name: temp-data
        path: /tmp/temp-data
